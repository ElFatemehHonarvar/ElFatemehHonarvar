{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNauuKOcnmpeXr53YAhtrpb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElFatemehHonarvar/ElFatemehHonarvar/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnJBDuFv0yAb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1, 2, 3], [4, 5, 6]]\n",
        "b = [[1, 2, 3]]\n",
        "print(torch.tensor(a).shape)\n",
        "print(torch.tensor(b).shape)\n",
        "\n",
        "print(torch.tensor(a) + torch.tensor(b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZkirQNF1OCH",
        "outputId": "f13d3589-87be-4d3e-d49a-5585b8c2d89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([1, 3])\n",
            "tensor([[2, 4, 6],\n",
            "        [5, 7, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1, 2, 3, -1], [4, 5, 6, 0]]\n",
        "b = [[1, 2]]\n",
        "print(torch.tensor(a).shape)\n",
        "print(torch.tensor(b).shape)\n",
        "\n",
        "print(torch.tensor(a) + torch.tensor(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cYhNbJyO1iNQ",
        "outputId": "bb92bcbd-ac7c-4361-adb4-4f0b8e90be34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "torch.Size([1, 2])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b13e0beb3765>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(a).view(8, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BDy-48V1qLb",
        "outputId": "0736c85e-6fff-4132-b538-0b43644b90c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1],\n",
              "        [ 2],\n",
              "        [ 3],\n",
              "        [-1],\n",
              "        [ 4],\n",
              "        [ 5],\n",
              "        [ 6],\n",
              "        [ 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1, 2, 3], [4, 5, 6]]\n",
        "b = [[1, 2, 3]]\n",
        "\n",
        "tensor_a = torch.tensor(a)\n",
        "tensor_b = torch.tensor(b)\n",
        "print(f\"shape a is {tensor_a.shape}\")\n",
        "print(f\"shape b is {tensor_b.shape}\")\n",
        "\n",
        "tensor_b = tensor_b.view(3, 1)\n",
        "print(tensor_a.matmul(tensor_b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9KGF5nP4Ijy",
        "outputId": "949c2604-52d7-4640-b0eb-6c9b97f592f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape a is torch.Size([2, 3])\n",
            "shape b is torch.Size([1, 3])\n",
            "tensor([[14],\n",
            "        [32]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inter-convert tensors with numpy arrays"
      ],
      "metadata": {
        "id": "wg5eG96C6qHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_a = tensor_a.numpy()\n",
        "print(f\" array a is {array_a}\")\n",
        "\n",
        "tensor_a = torch.tensor(array_a)\n",
        "print(f\" tensor a is {tensor_a}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afeMA6nT4iW9",
        "outputId": "85f0965f-1a63-4615-be63-7bccea03e7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " array a is [[1 2 3]\n",
            " [4 5 6]]\n",
            " tensor a is tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** : One of the reasons why we use **tensors** is vectorized oprations, operations that be conducted in parallel over a particular dimension of tensor. Essentially we can parallelize a lot of different computations and do them, for instance, across a batch of data"
      ],
      "metadata": {
        "id": "FW3Cmv3E94Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_a\n",
        "tensor_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qpk0Kfm8QtH",
        "outputId": "dab79fd6-f2ff-4dd9-c1a0-eaa5eb2ddd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_b.sum(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axAfshzX-9AY",
        "outputId": "f186baee-bdb5-4855-b194-63c8aa6563d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_c = torch.tensor([[[1, 2, 3]]])\n",
        "print(f\"tensor is  {tensor_c}, shape is {tensor_c.shape}\")\n",
        "# the dimension that you specify in the sum is the dimension you're collapsing.\n",
        "\n",
        "print(f\"sum over dim = 0  is {tensor_c.sum(dim=0)}, shape is {tensor_c.sum(dim=0).shape} \")\n",
        "print(f\"sum over dim = 1  is {tensor_c.sum(dim=1)}, shape is {tensor_c.sum(dim=1).shape}\")\n",
        "print(f\"sum over dim = 2  is {tensor_c.sum(dim=2)}, shape is {tensor_c.sum(dim=2).shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdZ0EQX-_DpZ",
        "outputId": "4d1d0876-6016-4693-85aa-1893c8aab354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor is  tensor([[[1, 2, 3]]]), shape is torch.Size([1, 1, 3])\n",
            "sum over dim = 0  is tensor([[1, 2, 3]]), shape is torch.Size([1, 3]) \n",
            "sum over dim = 1  is tensor([[1, 2, 3]]), shape is torch.Size([1, 3])\n",
            "sum over dim = 2  is tensor([[6]]), shape is torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** : But it's not just sum. You can compute standard deviations. You can normalize your data. You can do other operations, which essentially batch across the entire set of data."
      ],
      "metadata": {
        "id": "gSHsLUGTDRv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you don't specify any dimensions, then by default, the operation actually applies to the entire tensor.\n",
        "tensor_c.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-ECyYMr_yfy",
        "outputId": "f286d114-41a1-4922-ea71-651e1c5f6f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_d = torch.tensor([[1, 2.2, 9.6], [4, -7.2, 6.3]])\n",
        "\n",
        "print(f\"tensor is  {tensor_d}, shape is {tensor_d.shape}\")\n",
        "print(\"-\"*50)\n",
        "\n",
        "col_avg = tensor_d.mean(dim=0)\n",
        "print(f\"mean over dim = 0  is {col_avg}, shape is {col_avg.shape}\")\n",
        "\n",
        "row_avg = tensor_d.mean(dim=1)\n",
        "# If we're taking the average Over Rows, then an object that's 2x3, should just become an object that's 2.\n",
        "print(f\"mean over dim = 1  is {row_avg}, shape is {row_avg.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-EfiT50Ct8x",
        "outputId": "04aadc57-47c4-44ec-b0a3-53c9af584c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor is  tensor([[ 1.0000,  2.2000,  9.6000],\n",
            "        [ 4.0000, -7.2000,  6.3000]]), shape is torch.Size([2, 3])\n",
            "--------------------------------------------------\n",
            "mean over dim = 0  is tensor([ 2.5000, -2.5000,  7.9500]), shape is torch.Size([3])\n",
            "mean over dim = 1  is tensor([4.2667, 1.0333]), shape is torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sNHfHZfoGDj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Indexing**\n",
        "\n",
        "You can access arbitrary elements of a tensor using the ``[]`` operator\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1LnN0T1IkEth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_e = torch.tensor([\n",
        "    [[1, 2, 3], [0, -1, -2]], [[4, 5, 6], [0, -3, -4]]\n",
        "])\n",
        "tensor_e.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CWdrmAckfgU",
        "outputId": "62fe2a76-7116-41d6-ae93-ab3e1ad90291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the 0th element which is the first row\n",
        "tensor_e[0] # Equivalent to tensor_e[0, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpYX5pFilkQY",
        "outputId": "1c581798-0c83-423c-8978-1e9447616263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3],\n",
              "        [ 0, -1, -2]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_e[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPkJj4YOnZ3e",
        "outputId": "1aa24810-c669-48c5-c037-216219fa738a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "x[0, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NEfh16bmKui",
        "outputId": "31c3fc06-1605-43e1-c4ba-ebae86bc3393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f = torch.arange(1, 31, 2).view(5, 3)\n",
        "tensor_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ukuRhdnOpL",
        "outputId": "8c15008f-80d3-4b74-cdfe-65e4646c463a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  3,  5],\n",
              "        [ 7,  9, 11],\n",
              "        [13, 15, 17],\n",
              "        [19, 21, 23],\n",
              "        [25, 27, 29]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[0, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AfMv_gipVnU",
        "outputId": "815d8bc1-fd22-471a-978a-51253c088cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[0, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HNPpX8Sp9By",
        "outputId": "bd5de034-2d26-4157-9df4-72f2bbfee932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[0:2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHu11-eBqCUG",
        "outputId": "ca4ab0d5-ae40-414a-cd9c-89c1dfadf615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  3,  5],\n",
              "        [ 7,  9, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[3, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNUpP1fsqUDb",
        "outputId": "9806b441-ae13-4467-d479-6b336e05d045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(21)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[:, 1:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUEgMeIyqkIt",
        "outputId": "a338c4e9-8d04-4015-c23b-4715ff4cb2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3],\n",
              "        [ 9],\n",
              "        [15],\n",
              "        [21],\n",
              "        [27]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[:, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRBn7ihfqozw",
        "outputId": "7c8abbb7-3f53-441a-d0ea-58ab72340d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3,  9, 15, 21, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[0:3, 0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHFwtvBNrIlB",
        "outputId": "8b206a78-885f-4c6e-9bfb-1352e39526c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  3],\n",
              "        [ 7,  9],\n",
              "        [13, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[0:3, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3HJpr7zr4Jv",
        "outputId": "9c441212-0020-4f76-fe78-5e5925a79216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 11, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[0:3][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7qRoIqwsEx1",
        "outputId": "fcb4bfa3-7c51-4f2d-c178-174162abcfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13, 15, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[3, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6tNxTA3sNXV",
        "outputId": "3d1aabf9-1762-48ae-e3e4-62e626a67c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(23)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[3][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvK8rN8bsX7-",
        "outputId": "54f3f81e-3e25-4724-ee81-8be944a30331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(23)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list indexing\n",
        "tensor_f[[0, 2, 4]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBrRkOVmsb9_",
        "outputId": "f5f277ea-0b01-4b58-fe4e-94169436b2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  3,  5],\n",
              "        [13, 15, 17],\n",
              "        [25, 27, 29]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_f[:,[0, 2]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztZOYSpjs56K",
        "outputId": "7513d5d4-62a7-49bd-a3e6-aeb39cb5b92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  5],\n",
              "        [ 7, 11],\n",
              "        [13, 17],\n",
              "        [19, 23],\n",
              "        [25, 29]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUqTQa3kt5BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_g = torch.arange(1, 13, dtype=torch.float32).view(3, 2, 2)\n",
        "tensor_g\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEOvS0eYu-ui",
        "outputId": "e86cb25f-52a3-4cdc-f8c7-b19ca47d1548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  2.],\n",
              "         [ 3.,  4.]],\n",
              "\n",
              "        [[ 5.,  6.],\n",
              "         [ 7.,  8.]],\n",
              "\n",
              "        [[ 9., 10.],\n",
              "         [11., 12.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_g[0, :, :] # Equivalent to tensor_g[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEU9sg_JvvVi",
        "outputId": "ab5661a5-dbbc-4e3f-eb5a-a1e8d4d2e0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_g[0, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49CROF3nv_JO",
        "outputId": "4707cb56-797b-448c-9c31-e120f0c2f3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** : when we're writing code with neural networks,ultimately, we're going to process\n",
        "some data through a network and we're going to get a loss. And that loss needs to be a scalar. And then we're going to compute gradients, with respect to that loss. So one thing to keep in mind is that sometimes you might have an operation and it fails because it was actually expecting a scalar value rather than a tensor.\n",
        "\n",
        "We can get a ``Python`` scalar value from a tensor with ``item():``"
      ],
      "metadata": {
        "id": "DUIwNrAfxAH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_g[0, 1, 1].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSEthcymwILn",
        "outputId": "90ac7a0f-498a-4e63-a1d3-1d297020f6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd\n",
        "PyTorch is well-known for its automatic differentiation feature. We can call backward call the ``backward()`` method to ask ``PyTorch`` to calculate the gradients, which are then stored in the ``grad`` attribute.\n",
        "\n",
        "Detailed explanation:\n",
        "\n",
        "PyTorch essentially provides an automatic differentiation package where when you define your neural network, you're essentially defining many nodes that\n",
        "compute some function. And in the forward pass, you're kind of running your data through those nodes. But what PyTorch is doing on the back end, is that at each of those points, it's going to actually store the gradients and accumulate them, so that every time you do your backwards pass, you apply the chain rule to be able to calculate all of these different gradients. And PyTorch caches those gradients. And then you will have access to all of those gradients to be able to actually then run your favorite optimizer and optimize with SGD, or with Adam, or whichever optimizer you choose.\n",
        "\n",
        "summary : y.backward() will perform backprop to compute the gradients for all the leaf Tensors used to compute y.\n",
        "The .grad attribute of leaf Tensors is where these computed gradients are stored.\n",
        "In the backwards pass, what it's doing is you can imagine there's the x tensor\n",
        "and then there's the ``.grad`` attribute, which is another separate tensor. It's going to be the same shape as x. And what that is storing, is it's storing the accumulated gradient from every single time that you've called ``.backward()`` on a quantity that essentially has some dependency on x, that will have a non-zero gradient.\n",
        "\n",
        "\n",
        "More info :\n",
        "https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
      ],
      "metadata": {
        "id": "-J4ZZp_P3BkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.], requires_grad=True)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "RVc0QG4bxh9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88c408f-0b3d-4d98-e49b-388cff13418a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "``requires_grad`` parameter tells PyTorch to store gradients\n",
        "\n",
        "why do we have this when we always want to store the gradient?\n",
        "\n",
        "the answer is, at train time, you need the gradients in order to actually train your network. But at inference time, you'd actually want to disable your gradients. And you can actually do that because it's a lot of extra computation that's not needed, since you're not making any updates to your network anymore.\n",
        "you need to zero out the gradient because you don't want the previous gradients\n",
        "from the last epoch where you iterated through all of your training data to mess with the current update that you're doing.\n"
      ],
      "metadata": {
        "id": "FchtWcD87FJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.], requires_grad=True)\n",
        "\n",
        "# we've essentially made two different backwards passes. We've called it once\n",
        "# on this function y, which is a function of x. And we've called it once on z,\n",
        "# which is also a function of x.\n",
        "y = x * x * 3\n",
        "y.backward()\n",
        "print(x.grad)\n",
        "\n",
        "z = x * x * 3\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx_Z1eIV8EUb",
        "outputId": "dbc9876d-18a4-4c58-8ea6-5ed9b7e905da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([12.])\n",
            "tensor([24.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**bold text** Add description"
      ],
      "metadata": {
        "id": "aL9Qx_QsGR7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Module\n",
        "\n",
        "we're going to be defining neural networks in terms of existing building blocks, in terms of existing APIs, which will implement for instance linear layers or different activation functions that we need."
      ],
      "metadata": {
        "id": "4omVlo6eHMbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "hhavI8ge9Mw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The way the linear layer works in PyTorch, is it takes in two arguments. It takes in the input dimension and then the output dimension. And so what it does, is it takes in some input, which has some arbitrary amount of dimensions,\n",
        "and then finally, the input dimension. And it will essentially output it to that same set of dimensions, except the output dimension and the very last place.\n",
        "\n",
        "\n",
        "Typically, we think of the first dimension as the batch dimension. So in this case, it said ``N`` this you can think of as if you had a batch of images,\n",
        "it would be the number of images. If you had a training corpus of text,\n",
        "it would be essentially the number of sentences or sequences.\n",
        "\n",
        "The star indicates that there can be an arbitrary number of dimensions. So for instance, if we had images, this could be a 4-dimensional tensor object. It could be the batch size by the number of channels by the height, by the width.\n",
        "But in general, there's no fixed number of dimensions.\n",
        "\n",
        "Your input tensor can be any number of dimensions.The key is just that last dimension needs to match up with the input dimension of your linear layer.\n",
        "\n",
        "So essentially, we're saying that we're going to map this last dimension, which\n",
        "is 4-dimensional to now 2-dimensional. So in general, you can think of this as if we're stacking a neural network, 5 in nn.Linear(5, 1) is the kind of input dimension size.And 1 in nn.Linear(5, 1) would be like the hidden dimension size."
      ],
      "metadata": {
        "id": "EsehKRBhKHRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Layer"
      ],
      "metadata": {
        "id": "lc3e6WYnHldZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.ones(2, 3, 5)\n",
        "\n",
        "linear = nn.Linear(5, 1)\n",
        "output = linear(input)\n",
        "print(output.shape)\n",
        "print(\"-------------\")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfyU6GoqHfUI",
        "outputId": "770d3bef-b6a7-4c4d-825a-a0ddca12aecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 1])\n",
            "-------------\n",
            "tensor([[[0.4913],\n",
            "         [0.4913],\n",
            "         [0.4913]],\n",
            "\n",
            "        [[0.4913],\n",
            "         [0.4913],\n",
            "         [0.4913]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have this grad function ``grad_fn``. And so that's because we're actually computing and storing the gradients here for our tensor."
      ],
      "metadata": {
        "id": "unkj_OyAKFkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# And so both of them store the gradients.And in this case, these are what the current values of these parameters are.And they'll change as we trained the network.\n",
        "list(linear.parameters())   # Ax + b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKHQFgxuIcl2",
        "outputId": "92a14ad7-bbb2-4549-ad91-35b4ad978a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.1817,  0.3444, -0.4287, -0.1835, -0.0045]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1396], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block = nn.Sequential(\n",
        "    nn.Linear(5, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "input = torch.ones(2, 3, 5)\n",
        "output = block(input)\n",
        "output"
      ],
      "metadata": {
        "id": "cX3u145gIsE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47410248-f057-42a9-f315-e6c703a68da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5247],\n",
              "         [0.5247],\n",
              "         [0.5247]],\n",
              "\n",
              "        [[0.5247],\n",
              "         [0.5247],\n",
              "         [0.5247]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "  def __init__(self, input_size , hidden_size):\n",
        "    super(MultilayerPerceptron, self).__init__()   # super is an object from main class,nn.Modul. here we bound the main class to MultilayerPerceptron and its objest,self.\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input_size, self.hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size, self.input_size),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ydbBFgCCL-4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super(MultilayerPerceptron) # unbound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI9K_aAlo9cL",
        "outputId": "93040d25-c89c-43fe-90ec-9333e2b82ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<super: __main__.MultilayerPerceptron, None>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-gLpGhp_pIN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(2, 5)\n",
        "model = MultilayerPerceptron(5, 3)\n",
        "model(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t5waT7f7d2B",
        "outputId": "4e033637-414e-41a6-d6bc-d6822be8a6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7216, 0.5806, 0.3648, 0.3676, 0.4173],\n",
              "        [0.6102, 0.5158, 0.4536, 0.4386, 0.4934]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "super(MultilayerPerceptron, model) #bound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wmOT4wApNEU",
        "outputId": "25885cbd-7f5d-4205-9086-b579abad6213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<super: __main__.MultilayerPerceptron,\n",
              "        MultilayerPerceptron(\n",
              "          (model): Sequential(\n",
              "            (0): Linear(in_features=5, out_features=3, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=3, out_features=5, bias=True)\n",
              "            (3): Sigmoid()\n",
              "          )\n",
              "        )>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHrR2UFD9gK1",
        "outputId": "15ff443d-6695-43a0-e396-05d8cf91162f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3328, 0.5894, 0.5448, 0.4074, 0.6427],\n",
              "        [0.4010, 0.5857, 0.5591, 0.4121, 0.6242]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason ``model(input)`` and ``model.forward(input)`` yield the same results is due to how PyTorch's nn.Module class is designed.\n",
        "\n",
        "When you call ``model(input)``, it internally invokes the ``__call__ ``method of ``nn.Module``, which is built into every PyTorch model. The ``__call__`` method, in turn, calls the forward method you defined in your model. Therefore, ``model(input)`` is effectively the same as ``model.forward(input)``.\n",
        "\n",
        "``model.forward(input)`` directly calls the forward method, bypassing any additional functionality provided by ``__call__``, such as hooks, which PyTorch uses for things like logging, profiling, or modifying inputs and outputs."
      ],
      "metadata": {
        "id": "qFpR3AYuBx2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.named_parameters())\n"
      ],
      "metadata": {
        "id": "lhTXxZKJ-Tu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e3407f-48e5-4603-fd43-54955dd8349f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('model.0.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[ 0.3469, -0.2862, -0.1382, -0.1603, -0.3757],\n",
              "          [ 0.3582, -0.0254,  0.3075,  0.0823, -0.3236],\n",
              "          [ 0.1594, -0.3484, -0.1925,  0.3264, -0.0264]], requires_grad=True)),\n",
              " ('model.0.bias',\n",
              "  Parameter containing:\n",
              "  tensor([-0.4370, -0.4294, -0.2770], requires_grad=True)),\n",
              " ('model.2.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.5521,  0.4971, -0.1844],\n",
              "          [ 0.1914,  0.5041,  0.0373],\n",
              "          [-0.1350,  0.1558,  0.3496],\n",
              "          [-0.0565,  0.0993,  0.3199],\n",
              "          [-0.0483, -0.2651, -0.1678]], requires_grad=True)),\n",
              " ('model.2.bias',\n",
              "  Parameter containing:\n",
              "  tensor([ 0.2900,  0.5341, -0.3321, -0.4505,  0.2494], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to train a network?"
      ],
      "metadata": {
        "id": "wrYY5iFRAZYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimization\n",
        "# opdate the parameters using those gradients\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "7wm4ZHLqAIAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.ones(10, 5)\n",
        "x = y + torch.randn_like(y)  # y + noise"
      ],
      "metadata": {
        "id": "dvFdKSlkBX1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultilayerPerceptron(5, 3)\n",
        "\n",
        "# optimizer\n",
        "adam_optim = optim.Adam(model.parameters() ,lr=1e-1)\n",
        "\n",
        "# loss function  -> here the loss is cross entropy loss\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "y_pred = model(x)\n",
        "loss_function(y_pred, y).item()  # .item()    to extract scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx3d2gRpCVym",
        "outputId": "40d8755f-6df8-47b1-bea2-a99efbc95b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8946205973625183"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 10\n",
        "for epoch in torch.arange(n_epoch):\n",
        "\n",
        "  adam_optim.zero_grad()\n",
        "  y_pred = model(x)\n",
        "  loss = loss_function(y_pred, y)\n",
        "  print(type(loss))\n",
        "  print(f\"epoch : {epoch}, loss : {loss}\")\n",
        "\n",
        "  # computes all the gradients in the backward pass from our loss\n",
        "  loss.backward()\n",
        "\n",
        "  adam_optim.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKWlN4rBFK8F",
        "outputId": "1e496cb3-9ed7-40b4-d668-eb0397a65d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "epoch : 0, loss : 0.177326962351799\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 1, loss : 0.1085415929555893\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 2, loss : 0.061373766511678696\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 3, loss : 0.032618504017591476\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 4, loss : 0.016694240272045135\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 5, loss : 0.008397682569921017\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 6, loss : 0.004193254746496677\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 7, loss : 0.002120769117027521\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 8, loss : 0.0011030498426407576\n",
            "<class 'torch.Tensor'>\n",
            "epoch : 9, loss : 0.0005926700541749597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code snippet you provided, let's break down the key parts:\n",
        "\n",
        "1. **`loss.backward()`**:\n",
        "   - This line initiates the *backward pass* in the neural network, which calculates the gradients of the loss with respect to each of the model parameters.\n",
        "   - Specifically, it leverages the chain rule to compute these gradients for all the parameters that contributed to the output.\n",
        "   - When you call `loss.backward()`, it populates the `.grad` attributes of each parameter in your model with the gradient values.\n",
        "   - These gradients are later used by the optimizer (here, `adam_optim`) to update the model's parameters, allowing the model to learn from the data.\n",
        "\n",
        "2. **Why is `loss.item()` not used in the print statement?**\n",
        "   - Normally, `loss.item()` is used to retrieve the raw Python float value of the loss tensor for display or logging. Without `.item()`, `loss` will still be a tensor, but this doesn’t cause an error with `print()` because the `print()` function can handle tensor objects and will automatically convert them to a readable format.\n",
        "   - By omitting `.item()`, you keep `loss` as a tensor. In PyTorch, keeping loss as a tensor instead of converting it to a scalar doesn’t affect the code’s functionality here since it's only being printed, not used in any calculations."
      ],
      "metadata": {
        "id": "SON3ADR0Yw06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you see the loss as a number in the print statement, it’s because the `print()` function displays the tensor’s scalar value (like a number) for easy readability. However, even though `loss` appears as a number, it’s actually a **tensor object** with a lot of underlying information that PyTorch uses during backpropagation.\n",
        "\n",
        "Here’s how it works in more detail:\n",
        "\n",
        "1. **Loss as a Tensor with Gradient Tracking**:\n",
        "   - In PyTorch, when you compute a loss (e.g., using a loss function like `MSELoss` or `CrossEntropyLoss`), the resulting `loss` is a tensor with a single scalar value.\n",
        "   - However, it’s not just any number; it’s a tensor that keeps track of the computation history and the operations that led to its value. This is because PyTorch tracks these operations in a *computational graph* whenever `requires_grad=True` is set on any tensor involved in the calculations.\n",
        "\n",
        "2. **Backward Propagation Using `loss.backward()`**:\n",
        "   - When you call `loss.backward()`, PyTorch uses the computational graph stored with `loss` to compute gradients for each parameter in the model with respect to this loss. This graph tells PyTorch how each parameter contributed to the final loss value.\n",
        "   - Since `loss` retains this graph, it can trace back through each operation, compute partial derivatives, and populate the `.grad` attributes of the model’s parameters.\n",
        "\n",
        "3. **Printing vs. Using in Backward Pass**:\n",
        "   - While `print(loss)` displays the scalar value for readability, `loss` as a tensor is much more complex. This underlying information (the computational graph) makes `loss` usable in `loss.backward()`.\n",
        "\n",
        "In summary, although `print(loss)` shows a simple number, the tensor contains all the necessary information for `loss.backward()` to work properly by retaining the computation history for gradient calculation."
      ],
      "metadata": {
        "id": "522GWu4WY2As"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ZmM7vS7Fs-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets   # this is correspond to Hugging Face transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nlIhIH8WJyOh",
        "outputId": "1e9bfff5-5361-47d5-b302-aaf392cec49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's practise"
      ],
      "metadata": {
        "id": "csdKXCYOxnOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets  # We will use datasets from torchvision to load the MNIST handwritten digits dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "bVLbozImJ4-w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pa7DvLyr6cgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoWInZ1ayxkK",
        "outputId": "ace625ad-4c36-4e56-829e-8433b1602942"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 46.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f_coxrb1Hmp",
        "outputId": "16d4ead3-b65b-4eec-c648-07678d15b5a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train_data: {train}\")\n",
        "print(f\"test_data: {test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dprY0k9u64qx",
        "outputId": "9cd6abdf-57fa-4890-bc89-8d56cbc86b8d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data: Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "test_data: Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_data_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "test_data_loader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for x,y in test_data_loader:\n",
        "  print(f\"shape of data : {x.shape}\")\n",
        "  print(f\"shape of label : {y.shape}\")\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrMi8vcA7F7f",
        "outputId": "5997b810-ff5e-4475-9d36-b1fb584baff2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data : torch.Size([64, 3, 32, 32])\n",
            "shape of label : torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_test ,label_test = next(iter(test_data_loader))  # test_data_loader -> iterable & iter(test_data_loader) -> iterator\n",
        "\n",
        "print(f\"data : {images_test}\")\n",
        "print(f\"label : {label_test}\")\n",
        "\n",
        "print(f\"shape of data : {images_test.shape}\")\n",
        "print(f\"shape of label : {label_test.shape}\")\n",
        "\n",
        "print(\"--------------------\"*10)\n",
        "print(f\"shape of data : {images_test[0]}\")\n",
        "print(f\"shape of label : {label_test[0]}\")\n",
        "print(f\"shape of data : {images_test[0].shape}\")\n",
        "print(f\"shape of label : {label_test[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPvNleKU84TX",
        "outputId": "daad9d82-0130-451b-9976-5879278c86fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data : tensor([[[[0.6784, 0.6627, 0.6627,  ..., 0.5451, 0.5412, 0.5373],\n",
            "          [0.6980, 0.6824, 0.6824,  ..., 0.5608, 0.5569, 0.5529],\n",
            "          [0.7176, 0.7020, 0.6980,  ..., 0.5765, 0.5725, 0.5647],\n",
            "          ...,\n",
            "          [0.8980, 0.8980, 0.9020,  ..., 0.6510, 0.8235, 0.8392],\n",
            "          [0.9137, 0.8980, 0.9098,  ..., 0.8667, 0.9137, 0.9137],\n",
            "          [0.9137, 0.8980, 0.9020,  ..., 0.9098, 0.9059, 0.9098]],\n",
            "\n",
            "         [[0.8275, 0.8078, 0.8078,  ..., 0.7059, 0.7020, 0.6980],\n",
            "          [0.8471, 0.8275, 0.8275,  ..., 0.7176, 0.7137, 0.7098],\n",
            "          [0.8588, 0.8392, 0.8392,  ..., 0.7255, 0.7176, 0.7137],\n",
            "          ...,\n",
            "          [0.8941, 0.8941, 0.8980,  ..., 0.6784, 0.8431, 0.8549],\n",
            "          [0.9098, 0.8941, 0.9059,  ..., 0.8667, 0.9098, 0.9176],\n",
            "          [0.9137, 0.8980, 0.9020,  ..., 0.9098, 0.9059, 0.9098]],\n",
            "\n",
            "         [[1.0000, 0.9843, 0.9843,  ..., 0.9255, 0.9216, 0.9176],\n",
            "          [1.0000, 0.9961, 1.0000,  ..., 0.9373, 0.9294, 0.9255],\n",
            "          [1.0000, 1.0000, 0.9961,  ..., 0.9373, 0.9294, 0.9255],\n",
            "          ...,\n",
            "          [0.8863, 0.8863, 0.8902,  ..., 0.7020, 0.8627, 0.8706],\n",
            "          [0.9020, 0.8863, 0.8980,  ..., 0.8549, 0.9020, 0.9137],\n",
            "          [0.9059, 0.8902, 0.8941,  ..., 0.8980, 0.8980, 0.9020]]],\n",
            "\n",
            "\n",
            "        [[[0.8471, 0.8353, 0.8196,  ..., 0.8196, 0.8118, 0.8039],\n",
            "          [0.8706, 0.8588, 0.8431,  ..., 0.8235, 0.8196, 0.8118],\n",
            "          [0.8549, 0.8510, 0.8510,  ..., 0.8118, 0.8078, 0.8000],\n",
            "          ...,\n",
            "          [0.1765, 0.1804, 0.1843,  ..., 0.1686, 0.1765, 0.1804],\n",
            "          [0.1686, 0.1725, 0.1843,  ..., 0.1725, 0.1725, 0.1725],\n",
            "          [0.1608, 0.1608, 0.1647,  ..., 0.1608, 0.1569, 0.1569]],\n",
            "\n",
            "         [[0.8824, 0.8667, 0.8510,  ..., 0.8549, 0.8471, 0.8353],\n",
            "          [0.9059, 0.8941, 0.8784,  ..., 0.8588, 0.8549, 0.8431],\n",
            "          [0.8902, 0.8863, 0.8863,  ..., 0.8431, 0.8392, 0.8314],\n",
            "          ...,\n",
            "          [0.1961, 0.1961, 0.2000,  ..., 0.1882, 0.1961, 0.2000],\n",
            "          [0.1882, 0.1922, 0.2000,  ..., 0.1922, 0.1922, 0.1922],\n",
            "          [0.1765, 0.1765, 0.1804,  ..., 0.1765, 0.1725, 0.1725]],\n",
            "\n",
            "         [[0.9176, 0.9059, 0.8941,  ..., 0.8902, 0.8824, 0.8745],\n",
            "          [0.9412, 0.9294, 0.9137,  ..., 0.8941, 0.8902, 0.8824],\n",
            "          [0.9255, 0.9216, 0.9216,  ..., 0.8824, 0.8784, 0.8745],\n",
            "          ...,\n",
            "          [0.2078, 0.2118, 0.2118,  ..., 0.2000, 0.2078, 0.2118],\n",
            "          [0.2000, 0.2039, 0.2118,  ..., 0.2039, 0.2039, 0.2039],\n",
            "          [0.1882, 0.1882, 0.1922,  ..., 0.1843, 0.1882, 0.1843]]],\n",
            "\n",
            "\n",
            "        [[[0.1451, 0.1451, 0.1451,  ..., 0.1412, 0.1255, 0.1333],\n",
            "          [0.1451, 0.1451, 0.1451,  ..., 0.1490, 0.1255, 0.1333],\n",
            "          [0.1451, 0.1451, 0.1451,  ..., 0.1294, 0.1294, 0.1333],\n",
            "          ...,\n",
            "          [0.8196, 0.8353, 0.8314,  ..., 0.7255, 0.7255, 0.7137],\n",
            "          [0.9882, 0.9765, 0.9843,  ..., 0.8784, 0.8784, 0.8745],\n",
            "          [0.9765, 0.9686, 0.9882,  ..., 0.9765, 0.9804, 0.9804]],\n",
            "\n",
            "         [[0.1059, 0.1059, 0.1098,  ..., 0.1333, 0.1059, 0.1137],\n",
            "          [0.1059, 0.1098, 0.1098,  ..., 0.1333, 0.1059, 0.1137],\n",
            "          [0.1059, 0.1059, 0.1059,  ..., 0.1020, 0.1098, 0.1216],\n",
            "          ...,\n",
            "          [0.8157, 0.8314, 0.8314,  ..., 0.7216, 0.7294, 0.7255],\n",
            "          [0.9647, 0.9608, 0.9686,  ..., 0.8588, 0.8706, 0.8627],\n",
            "          [0.9373, 0.9451, 0.9569,  ..., 0.9608, 0.9647, 0.9686]],\n",
            "\n",
            "         [[0.1373, 0.1255, 0.1176,  ..., 0.1255, 0.1255, 0.1333],\n",
            "          [0.1373, 0.1255, 0.1216,  ..., 0.1490, 0.1373, 0.1412],\n",
            "          [0.1373, 0.1333, 0.1333,  ..., 0.1451, 0.1451, 0.1412],\n",
            "          ...,\n",
            "          [0.7373, 0.7451, 0.7373,  ..., 0.6588, 0.6627, 0.6510],\n",
            "          [0.8941, 0.8863, 0.8902,  ..., 0.7608, 0.7725, 0.7569],\n",
            "          [0.8471, 0.8588, 0.8784,  ..., 0.8549, 0.8784, 0.8745]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.4902, 0.4275, 0.3569,  ..., 0.4549, 0.4549, 0.4549],\n",
            "          [0.5059, 0.4667, 0.3294,  ..., 0.4667, 0.4667, 0.4667],\n",
            "          [0.5137, 0.4706, 0.3529,  ..., 0.4863, 0.4863, 0.4784],\n",
            "          ...,\n",
            "          [0.7608, 0.7490, 0.7686,  ..., 0.5961, 0.6863, 0.6980],\n",
            "          [0.7569, 0.7373, 0.7529,  ..., 0.7255, 0.7255, 0.7137],\n",
            "          [0.7725, 0.7725, 0.7686,  ..., 0.7373, 0.7529, 0.7373]],\n",
            "\n",
            "         [[0.6980, 0.6078, 0.4353,  ..., 0.6549, 0.6549, 0.6549],\n",
            "          [0.7098, 0.6706, 0.3412,  ..., 0.6667, 0.6667, 0.6627],\n",
            "          [0.7176, 0.6667, 0.3451,  ..., 0.6863, 0.6863, 0.6784],\n",
            "          ...,\n",
            "          [0.7490, 0.7451, 0.7686,  ..., 0.5765, 0.6745, 0.6745],\n",
            "          [0.7451, 0.7294, 0.7412,  ..., 0.6980, 0.6941, 0.6863],\n",
            "          [0.7608, 0.7608, 0.7529,  ..., 0.7020, 0.7176, 0.7059]],\n",
            "\n",
            "         [[0.9647, 0.8353, 0.6000,  ..., 0.9137, 0.9137, 0.9020],\n",
            "          [0.9686, 0.9216, 0.4235,  ..., 0.9255, 0.9216, 0.9137],\n",
            "          [0.9804, 0.9020, 0.3804,  ..., 0.9333, 0.9373, 0.9373],\n",
            "          ...,\n",
            "          [0.7294, 0.7176, 0.7373,  ..., 0.5333, 0.6431, 0.6353],\n",
            "          [0.7255, 0.6980, 0.7020,  ..., 0.6667, 0.6667, 0.6549],\n",
            "          [0.7412, 0.7451, 0.7373,  ..., 0.6745, 0.6863, 0.6784]]],\n",
            "\n",
            "\n",
            "        [[[0.2314, 0.2392, 0.4824,  ..., 0.2235, 0.2039, 0.2902],\n",
            "          [0.2549, 0.2667, 0.5137,  ..., 0.2588, 0.2471, 0.2784],\n",
            "          [0.2863, 0.2980, 0.5412,  ..., 0.2980, 0.2824, 0.3020],\n",
            "          ...,\n",
            "          [0.0039, 0.0078, 0.0118,  ..., 0.2667, 0.2353, 0.2706],\n",
            "          [0.2627, 0.1804, 0.1843,  ..., 0.3255, 0.2902, 0.3255],\n",
            "          [0.6980, 0.5843, 0.5882,  ..., 0.5765, 0.5765, 0.6039]],\n",
            "\n",
            "         [[0.3882, 0.3647, 0.5608,  ..., 0.3765, 0.3647, 0.3961],\n",
            "          [0.4078, 0.3882, 0.5882,  ..., 0.4039, 0.3961, 0.3725],\n",
            "          [0.4353, 0.4157, 0.6157,  ..., 0.4353, 0.4275, 0.3882],\n",
            "          ...,\n",
            "          [0.0392, 0.0392, 0.0392,  ..., 0.3961, 0.3608, 0.3529],\n",
            "          [0.2706, 0.1843, 0.1843,  ..., 0.3882, 0.3490, 0.3647],\n",
            "          [0.6980, 0.5843, 0.5882,  ..., 0.6039, 0.6000, 0.6196]],\n",
            "\n",
            "         [[0.7922, 0.7804, 0.8039,  ..., 0.7961, 0.7686, 0.7098],\n",
            "          [0.8078, 0.8000, 0.8235,  ..., 0.8118, 0.7961, 0.6902],\n",
            "          [0.8235, 0.8196, 0.8471,  ..., 0.8275, 0.8118, 0.6980],\n",
            "          ...,\n",
            "          [0.0824, 0.1020, 0.1216,  ..., 0.4510, 0.4510, 0.4510],\n",
            "          [0.3176, 0.2392, 0.2549,  ..., 0.4588, 0.4314, 0.4431],\n",
            "          [0.7294, 0.6235, 0.6353,  ..., 0.6667, 0.6588, 0.6745]]],\n",
            "\n",
            "\n",
            "        [[[0.2510, 0.2549, 0.2627,  ..., 0.2627, 0.2549, 0.2510],\n",
            "          [0.2471, 0.2588, 0.2667,  ..., 0.2627, 0.2549, 0.2510],\n",
            "          [0.2431, 0.2549, 0.2667,  ..., 0.2627, 0.2588, 0.2510],\n",
            "          ...,\n",
            "          [0.2824, 0.2863, 0.2863,  ..., 0.2863, 0.2824, 0.2706],\n",
            "          [0.2824, 0.2824, 0.2863,  ..., 0.2863, 0.2824, 0.2706],\n",
            "          [0.2784, 0.2824, 0.2902,  ..., 0.2863, 0.2824, 0.2706]],\n",
            "\n",
            "         [[0.3020, 0.3098, 0.3176,  ..., 0.3216, 0.3137, 0.3098],\n",
            "          [0.3059, 0.3137, 0.3216,  ..., 0.3176, 0.3137, 0.3098],\n",
            "          [0.3137, 0.3176, 0.3216,  ..., 0.3176, 0.3098, 0.3059],\n",
            "          ...,\n",
            "          [0.3373, 0.3412, 0.3412,  ..., 0.3412, 0.3373, 0.3294],\n",
            "          [0.3373, 0.3373, 0.3412,  ..., 0.3412, 0.3373, 0.3294],\n",
            "          [0.3333, 0.3373, 0.3451,  ..., 0.3412, 0.3373, 0.3333]],\n",
            "\n",
            "         [[0.5843, 0.5882, 0.5961,  ..., 0.5922, 0.5843, 0.5804],\n",
            "          [0.5843, 0.5922, 0.6000,  ..., 0.5922, 0.5882, 0.5804],\n",
            "          [0.5882, 0.5961, 0.6000,  ..., 0.5961, 0.5922, 0.5843],\n",
            "          ...,\n",
            "          [0.6157, 0.6196, 0.6235,  ..., 0.6196, 0.6157, 0.6078],\n",
            "          [0.6157, 0.6196, 0.6196,  ..., 0.6196, 0.6157, 0.6078],\n",
            "          [0.6118, 0.6196, 0.6235,  ..., 0.6196, 0.6157, 0.6078]]]])\n",
            "label : tensor([9, 0, 7, 5, 4, 2, 3, 6, 4, 1, 0, 6, 2, 9, 1, 9, 4, 7, 7, 1, 6, 4, 0, 1,\n",
            "        0, 2, 6, 7, 6, 3, 9, 7, 1, 5, 5, 1, 7, 0, 0, 4, 3, 9, 0, 6, 5, 5, 8, 2,\n",
            "        4, 7, 9, 5, 3, 8, 0, 3, 5, 6, 4, 3, 8, 7, 8, 0])\n",
            "shape of data : torch.Size([64, 3, 32, 32])\n",
            "shape of label : torch.Size([64])\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "shape of data : tensor([[[0.6784, 0.6627, 0.6627,  ..., 0.5451, 0.5412, 0.5373],\n",
            "         [0.6980, 0.6824, 0.6824,  ..., 0.5608, 0.5569, 0.5529],\n",
            "         [0.7176, 0.7020, 0.6980,  ..., 0.5765, 0.5725, 0.5647],\n",
            "         ...,\n",
            "         [0.8980, 0.8980, 0.9020,  ..., 0.6510, 0.8235, 0.8392],\n",
            "         [0.9137, 0.8980, 0.9098,  ..., 0.8667, 0.9137, 0.9137],\n",
            "         [0.9137, 0.8980, 0.9020,  ..., 0.9098, 0.9059, 0.9098]],\n",
            "\n",
            "        [[0.8275, 0.8078, 0.8078,  ..., 0.7059, 0.7020, 0.6980],\n",
            "         [0.8471, 0.8275, 0.8275,  ..., 0.7176, 0.7137, 0.7098],\n",
            "         [0.8588, 0.8392, 0.8392,  ..., 0.7255, 0.7176, 0.7137],\n",
            "         ...,\n",
            "         [0.8941, 0.8941, 0.8980,  ..., 0.6784, 0.8431, 0.8549],\n",
            "         [0.9098, 0.8941, 0.9059,  ..., 0.8667, 0.9098, 0.9176],\n",
            "         [0.9137, 0.8980, 0.9020,  ..., 0.9098, 0.9059, 0.9098]],\n",
            "\n",
            "        [[1.0000, 0.9843, 0.9843,  ..., 0.9255, 0.9216, 0.9176],\n",
            "         [1.0000, 0.9961, 1.0000,  ..., 0.9373, 0.9294, 0.9255],\n",
            "         [1.0000, 1.0000, 0.9961,  ..., 0.9373, 0.9294, 0.9255],\n",
            "         ...,\n",
            "         [0.8863, 0.8863, 0.8902,  ..., 0.7020, 0.8627, 0.8706],\n",
            "         [0.9020, 0.8863, 0.8980,  ..., 0.8549, 0.9020, 0.9137],\n",
            "         [0.9059, 0.8902, 0.8941,  ..., 0.8980, 0.8980, 0.9020]]])\n",
            "shape of label : 9\n",
            "shape of data : torch.Size([3, 32, 32])\n",
            "shape of label : torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To accelerate operations in the neural network, we move it to the GPU or MPS (for Apple silicon) if available.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(device)\n",
        "\n",
        "\n",
        "# x= 4\n",
        "# y=10s\n",
        "# [x if x==y else y]  -> [10]\n",
        "# (x if x==y else y)  -> 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKm6M-oYAGxc",
        "outputId": "13b1b912-2026-4a2d-929d-49a7484997ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes\n",
        "classes = len(train.classes)  # Get the number of classes\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ8GP0-3KBeX",
        "outputId": "b191fea3-f3c6-4dcd-bb7e-1237d0df692d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For now we only want to use ``Linear`` layers so we must flatten the inputs so that we can pass it to the linear layers. The ``nn.Flatten()`` module allows us to do this.\n",
        "\n",
        "For a classification task with multiple classes, you should use ``nn.Softmax(dim=1)`` (for probabilities) or omit it if you're using ``CrossEntropyLoss``, which applies ``log_softmax`` internally."
      ],
      "metadata": {
        "id": "RvHlsi15IVZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    # self.input_size = input_size\n",
        "    # self.hidden_size = hidden_size\n",
        "    self.flatten =nn.Flatten()\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Linear(32*32*3, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    output = self.model(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "XR9h3122BPtx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftw_dSCXRvla",
        "outputId": "fde0e496-a7a8-4a01-e9bc-9767248be08a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "WgVcdMcPP-fA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we need to setup an optimizer for training our model. We use **stochastic gradient descent** so we must use the **``SGD``** module from torch.optim. We must pass the ``model.parameters()`` to the ``SGD`` optimizer and set its learning rate ``lr=1e-3``."
      ],
      "metadata": {
        "id": "CMEWnhJUQrAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "d5uyKDWQQUU-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "n_epoch = 50\n",
        "avg_loss = []\n",
        "for epoch in (pbar:=tqdm(range(n_epoch))):\n",
        "  for x, y in train_data_loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      optim.zero_grad()\n",
        "      y_pred = model(x)\n",
        "      loss = loss_func(y_pred, y)\n",
        "      avg_loss.append(loss.item())\n",
        "\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "  avg = sum(avg_loss) / len(avg_loss)\n",
        "  pbar.write(f\"Epoch {epoch + 1}, Loss: {avg:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vZeLPP0TCDf",
        "outputId": "23339ae9-7fa5-4bb6-b7ee-3cf96b3ce1b2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [00:19<16:16, 19.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.6296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 2/50 [00:40<16:24, 20.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1.6272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 3/50 [01:01<16:11, 20.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.6247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 4/50 [01:21<15:36, 20.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 1.6223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 5/50 [01:42<15:24, 20.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.6200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 6/50 [02:01<14:48, 20.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 1.6176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 7/50 [02:22<14:36, 20.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 1.6153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 8/50 [02:42<14:07, 20.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 1.6130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 9/50 [03:03<13:57, 20.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.6106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 10/50 [03:23<13:35, 20.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.6083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 11/50 [03:44<13:17, 20.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 1.6061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 12/50 [04:05<13:00, 20.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 1.6038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 13/50 [04:25<12:39, 20.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 1.6016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 14/50 [04:46<12:22, 20.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 1.5993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 15/50 [05:06<11:54, 20.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 1.5971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 16/50 [05:26<11:35, 20.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 1.5949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 17/50 [05:47<11:14, 20.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 1.5927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 18/50 [06:07<10:48, 20.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 1.5906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 19/50 [06:27<10:28, 20.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 1.5885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 20/50 [06:47<10:03, 20.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 1.5863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 21/50 [07:08<09:51, 20.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 1.5842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 22/50 [07:27<09:23, 20.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Loss: 1.5821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 23/50 [07:48<09:08, 20.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Loss: 1.5800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 24/50 [08:08<08:43, 20.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Loss: 1.5779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 25/50 [08:28<08:26, 20.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 1.5758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 26/50 [08:48<08:03, 20.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Loss: 1.5738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 27/50 [09:08<07:44, 20.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Loss: 1.5717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 28/50 [09:30<07:34, 20.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Loss: 1.5697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 29/50 [09:50<07:08, 20.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 1.5677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 30/50 [10:10<06:47, 20.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Loss: 1.5657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 31/50 [10:30<06:21, 20.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31, Loss: 1.5637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 32/50 [10:50<06:02, 20.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, Loss: 1.5617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 33/50 [11:10<05:44, 20.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 1.5598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 34/50 [11:31<05:24, 20.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Loss: 1.5578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 35/50 [11:52<05:07, 20.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35, Loss: 1.5559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 36/50 [12:11<04:43, 20.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Loss: 1.5540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 37/50 [12:32<04:25, 20.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Loss: 1.5520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 38/50 [12:52<04:02, 20.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Loss: 1.5501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 39/50 [13:13<03:45, 20.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Loss: 1.5482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 40/50 [13:33<03:23, 20.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Loss: 1.5463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 41/50 [13:54<03:04, 20.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Loss: 1.5444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 42/50 [14:14<02:43, 20.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42, Loss: 1.5426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 43/50 [14:35<02:24, 20.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Loss: 1.5407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 44/50 [14:56<02:03, 20.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Loss: 1.5389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 45/50 [15:16<01:42, 20.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Loss: 1.5370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 46/50 [15:37<01:22, 20.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Loss: 1.5352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 47/50 [15:57<01:00, 20.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Loss: 1.5334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 48/50 [16:17<00:40, 20.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Loss: 1.5315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 49/50 [16:38<00:20, 20.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Loss: 1.5298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [16:58<00:00, 20.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 1.5280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n_epochs = 30\n",
        "\n",
        "# for _ in (pbar := trange(n_epochs)):\n",
        "#     # Iterate over the data\n",
        "#     for x, y in train_dataloader:\n",
        "#         # Move the datapoints to same device as the model\n",
        "#         x, y = x.to(device), y.to(device)\n",
        "#         # Predict the output and perform the forward pass\n",
        "#         pred = model(x)\n",
        "#         # Compute prediction error\n",
        "#         loss = loss_fn(pred, y)\n",
        "#         # Backpropagation\n",
        "#         loss.backward()\n",
        "#         # Update the model weights\n",
        "#         optimizer.step()\n",
        "#         # Clear the gradients\n",
        "#         optimizer.zero_grad()\n",
        "#         # Update the progress bar\n",
        "#         pbar.set_description(f'Loss = {loss.item():.3f}')"
      ],
      "metadata": {
        "id": "lLj8rXlK59Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "``pbar := trange(n_epochs):``\n",
        "\n",
        "The walrus operator assigns the ``trange`` object to the variable ``pbar`` while also using it in the loop.\n",
        "This allows you to interact with the progress bar object (``pbar``) within the loop, such as updating its description with ``pbar.set_description``.\n",
        "\n",
        "You could achieve the same effect without the walrus operator like this:\n",
        "\n",
        "``\n",
        "pbar = trange(n_epochs)``\n",
        "\n",
        "``for _ in pbar:\n",
        "    pbar.set_description(f'Loss = {loss.item():.3f}')``\n",
        "    \n",
        "However, using the walrus operator makes the code more concise."
      ],
      "metadata": {
        "id": "XeDaR9TAWkEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the number of correctly classified and total labels\n",
        "correct, total = 0, 0\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    # Iterate over the test data\n",
        "    for x, y in test_data_loader:\n",
        "        # Move the datapoints to same device as the model\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        # Predict the output\n",
        "        logits = model(x)\n",
        "        # Get the predicted label\n",
        "        pred = torch.argmax(logits, axis=1)\n",
        "        # Update the number of correclty classified labels\n",
        "        correct += sum(pred == y).item()\n",
        "        # Update the number of total labels\n",
        "        total += pred.shape[0] # Adds the number of samples in the current batch (pred.shape[0]) to the total counter to keep track of the total number of samples evaluated.\n",
        "\n",
        "print(f'Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZHgxZOqa77RG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1031c50d-5aad-4afb-8882-5a7c1c56c0bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 42.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### let's break down code step by step\n",
        "``logits = model(x)`` :\n",
        "Feeds the input batch (x) through the model to compute the raw output (logits), which is a tensor of shape ``[batch_size, num_classes]``.\n",
        "Each value in ``logits`` represents the unnormalized prediction scores for a class.\n",
        "\n",
        "``pred = torch.argmax(logits, axis=1)`` : Converts the raw output (logits) into predicted class labels (pred) by taking the index of the class with the highest score for each sample in the batch.\n",
        "``torch.argmax(logits, axis=1)`` returns a tensor of size ``[batch_size]`` containing the predicted class indices.\n",
        "\n",
        "example:\n",
        "\n"
      ],
      "metadata": {
        "id": "_-GkYnbKGTiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> A = torch.randn(1, 2) # tensor([[-0.1278, -0.3047]])\n",
        ">>> print(\"Tensor-A:\", A) # torch.Size([1, 2])\n",
        ">>> print(torch.argmax(A, axis=1))  # tensor([0]) -> -0.1278\n",
        "\n",
        ">>> a = torch.randn(4, 4)\n",
        ">>> a\n",
        "tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
        "        [-0.7401, -0.8805, -0.3402, -1.1936],\n",
        "        [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
        "        [-1.6092,  0.5419, -0.2993,  0.3195]])\n",
        ">>> torch.argmax(a)\n",
        "tensor(0)\n",
        "\n",
        "\n",
        ">>> a = torch.randn(4, 4)\n",
        ">>> a\n",
        "tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
        "        [-0.7401, -0.8805, -0.3402, -1.1936],\n",
        "        [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
        "        [-1.6092,  0.5419, -0.2993,  0.3195]])\n",
        ">>> torch.argmax(a, dim=1)\n",
        "tensor([ 0,  2,  0,  1])\n",
        "\n",
        "\n",
        ">>> A = torch.randn(1, 3)\n",
        " tensor([[1.5726, 0.7617, 0.1560]])\n",
        ">>> print(\"Tensor-A:\", A)\n",
        ">>> print(torch.max(A, axis=0))\n",
        "torch.return_types.max(\n",
        "values=tensor([1.5726, 0.7617, 0.1560]),\n",
        "indices=tensor([0, 0, 0]))"
      ],
      "metadata": {
        "id": "fa7dwaIPHNtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Do some experiments to find the best optimizer for our task\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iWZUFVJqXHFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    # self.input_size = input_size\n",
        "    # self.hidden_size = hidden_size\n",
        "    self.flatten =nn.Flatten()\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Linear(32*32*3, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    output = self.model(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "FzBJDjbjpx7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n"
      ],
      "metadata": {
        "id": "oP3P_RtCpx8U"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "imTZ739Qpx8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ivrH6ZAEoq97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizers =['SGD', 'AdaGrad', 'RMSProp', 'Adam']\n",
        "\n",
        "def train_model(train_data, optimizer, n_epoch=5):\n",
        "  losses, accuracies = [], []\n",
        "  for epoch in  (pbar:=tqdm(range(n_epoch))):\n",
        "    running_loss, acc , total, correct = 0, 0, 0, 0\n",
        "    for x, y in train_data:\n",
        "      x,y = x.to(device), y.to(device)  # shape x : (batch_size, ...)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(x)\n",
        "      loss = loss_func(y_pred, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      pred = torch.argmax(y_pred, axis=1)\n",
        "      correct += sum(pred==y).item()\n",
        "      total += pred.shape[0]\n",
        "      running_loss += loss.item()\n",
        "    print(total, len(train_data))\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    acc = (correct / total) * 100\n",
        "    accuracies.append(acc)\n",
        "    losses.append(avg_loss)\n",
        "    return losses, accuracies\n",
        "\n",
        "def run(train_data_loder, optimizer_name):\n",
        "  if optimizer_name == 'SGD':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "  elif optimizer_name == 'Adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "  elif optimizer_name == 'AdaGrad':\n",
        "    optimizer = optim.AdaGrad(model.parameters(), lr=1e-3)\n",
        "  elif optimizer_name == 'RMSProp':\n",
        "    optimizer = optim.RMSProp(model.parameters(), lr=1e-3)\n",
        "  else:\n",
        "    raise ValueError(f\"Invalid optimizer name: {optimizer_name}\")\n",
        "\n",
        "  loss, acc = train_model(train_data_loader, optimizer)\n",
        "  print(f\"{optimizer_name}, loss = {loss}, accuracy= {acc}\")"
      ],
      "metadata": {
        "id": "0L0KTHOcXGbc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = DataLoader(train, batch_size=128)\n",
        "run(train_data_loader, \"SGD\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Hsm9zWWi9k",
        "outputId": "77b4c365-33a8-4a33-dd38-7ff0676d9300"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:19<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 391\n",
            "SGD, loss = [0.011218184535503387], accuracy= [49.816]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sdgvWCu5KdyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}